![[../../Pasted image 20231029163921.png]]

# 论文摘要
以往的人脸抗仿冒检测都将抗仿冒视为一个二分类问题. 很多人试图去抓住一些充分的仿冒线索和生成出来的缺陷. 二分类问题无法说明预测结果的依据(模型是否学习到真正的活体与攻击之间的差异). 在本篇论文中, 作者认为辅助监督在引导判别和泛化型线索上是很重要的.
作者提出了一个CNN-RNN框架, 采用pixel-wise的深度图监督方式和sequence-wise的rPRG信号监督方式;
此外, 作者还提出了一个新的人脸抗仿冒数据库SiW 特点是高分辨率+丰富的PIE; 试验在cross-test取得了sota
![[../../Pasted image 20231029200700.png]]
Figure 1: 传统的基于CNN的人脸抗仿冒方法大多利用二进制监督, 在CNN解空间较大时可能导致过拟合. 作者设计了一个新的架构去充分利用两种辅助信息作为监督.这样可以让目标具有泛化性并且做出可解释性更好的决策.
# Introduction
人脸展示攻击Presention Attack分为三种: 打印攻击(拿照片) 重放攻击(放视频) 3D mask攻击(人穿戴3d面具); 现今都是先进行活体检测再识别人脸;
RGB图像和视频是传统的输入. 但是这类输入具有缺陷.
以往研究将抗仿冒任务视为二分类任务有以下几个问题:
1. 图像失真是有不同模式的, 如:皮肤细节缺失, 颜色, 纹路, 形状变形等. 具有Softmax的CNN可能因为发现任意一种失真的模式就将它判定为假了
